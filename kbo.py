import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup

# 1. í˜ì´ì§€ ì„¤ì • (ì›¹ ë¸Œë¼ìš°ì € íƒ­ì— í‘œì‹œë  ì´ë¦„)
st.set_page_config(page_title="KBO ë°ì´í„° ë¶„ì„ê¸°", layout="wide")
st.title("âš¾ KBO ê³µì‹ ê¸°ë¡ì‹¤ & ì„ ìˆ˜ ê²€ìƒ‰")

# --- [ì„¹ì…˜ 1] íŒ€ ìˆœìœ„í‘œ ---
st.subheader("ğŸ† KBO ê³µì‹ íŒ€ ìˆœìœ„")
url_rank = "https://www.koreabaseball.com/Record/TeamRank/TeamRank.aspx"

try:
    # íŒ€ ìˆœìœ„ ê°€ì ¸ì˜¤ê¸°
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    response = requests.get(url_rank, headers=headers)
    df_rank = pd.read_html(response.text)[0]
    
    # ìƒë‹¨ ìš”ì•½ ì§€í‘œ (Metric)
    col1, col2, col3 = st.columns(3)
    col1.metric("í˜„ì¬ 1ìœ„", f"ğŸ† {df_rank.iloc[0]['íŒ€ëª…']}")
    col2.metric("ë¦¬ê·¸ ì§„í–‰", f"{df_rank.iloc[0]['ê²½ê¸°']} ê²½ê¸°")
    col3.metric("ìµœê³  ìŠ¹ë¥ ", f"{df_rank.iloc[0]['ìŠ¹ë¥ ']}")
    
    st.dataframe(df_rank, use_container_width=True, hide_index=True)

except Exception as e:
    st.error("íŒ€ ìˆœìœ„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

st.markdown("---") # êµ¬ë¶„ì„ 

# --- [ì„¹ì…˜ 2] 1êµ° ì„ ìˆ˜ ê²€ìƒ‰ ê¸°ëŠ¥ ---
st.header("ğŸ” 1êµ° ì„ ìˆ˜ ê²€ìƒ‰")

@st.cache_data(ttl=3600) # 1ì‹œê°„ ë™ì•ˆ ë°ì´í„°ë¥¼ ê¸°ì–µí•©ë‹ˆë‹¤.
def get_all_players():
    # KBO íŒ€ ì½”ë“œ ë§¤í•‘
    teams = {
        'OB':'ë‘ì‚°', 'LG':'LG', 'SK':'SSG', 'LT':'ë¡¯ë°', 'SS':'ì‚¼ì„±', 
        'HT':'KIA', 'HE':'í•œí™”', 'NC':'NC', 'KT':'KT', 'WO':'í‚¤ì›€'
    }
    player_data = []
    
    # ì ‘ì† ì°¨ë‹¨ì„ ë§‰ê¸° ìœ„í•œ í—¤ë” ì„¤ì •
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}

    for code, team_name in teams.items():
        try:
            url = f"https://www.koreabaseball.com/Player/Search.aspx?teamCode={code}"
            res = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # ì„ ìˆ˜ ëª©ë¡ í…Œì´ë¸” í–‰ ì°¾ê¸°
            rows = soup.select('.tEx tbody tr')
            for row in rows:
                cols = row.find_all('td')
                if len(cols) > 3:
                    p_name = cols[1].text.strip() # ì´ë¦„
                    p_pos = cols[3].text.strip()  # í¬ì§€ì…˜
                    player_data.append({'íŒ€': team_name, 'ì´ë¦„': p_name, 'í¬ì§€ì…˜': p_pos})
        except:
            continue
    
    # ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ í‘œ ë°˜í™˜
    if not player_data:
        return pd.DataFrame(columns=['íŒ€', 'ì´ë¦„', 'í¬ì§€ì…˜'])
    
    return pd.DataFrame(player_data)

# ì„ ìˆ˜ ë°ì´í„° ë¡œë“œ (ë¡œë”© ë°” í‘œì‹œ)
with st.spinner('ì „ì²´ 10ê°œ íŒ€ ì„ ìˆ˜ ëª…ë‹¨ì„ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...'):
    df_players = get_all_players()

# ê²€ìƒ‰ì°½ ì…ë ¥
search_query = st.text_input("ì°¾ê³  ì‹¶ì€ ì„ ìˆ˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ê¹€ë„ì˜, ê°•ë°±í˜¸, êµ¬ììš±")

if search_query:
    # ê²€ìƒ‰ì–´ ì •ì œ (ê³µë°± ì œê±° ë“±)
    clean_query = search_query.strip()
    
    if not df_players.empty and 'ì´ë¦„' in df_players.columns:
        # ì´ë¦„ì— ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ì„ ìˆ˜ í•„í„°ë§
        result = df_players[df_players['ì´ë¦„'].str.contains(clean_query)]
        
        if not result.empty:
            st.success(f"'{clean_query}' ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.")
            st.dataframe(result, use_container_width=True, hide_index=True)
        else:
            st.warning(f"'{clean_query}' ì„ ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„±ê³¼ ì´ë¦„ì„ ì •í™•íˆ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    else:
        st.error("í˜„ì¬ ì„ ìˆ˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ëŠ” ìƒíƒœì…ë‹ˆë‹¤. ì ì‹œ í›„ ìƒˆë¡œê³ ì¹¨(F5)ì„ í•´ì£¼ì„¸ìš”.")

st.snow() # ì„±ê³µ ê¸°ë… ëˆˆ ë‚´ë¦¬ê¸°